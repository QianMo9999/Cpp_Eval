"""
ä¸»ç¨‹åº - C++ä½œä¸šè‡ªåŠ¨è¯„ä»·ç³»ç»Ÿ
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›å®Œæ•´çš„è¯„ä»·æµç¨‹
"""
import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, current_dir)
sys.path.insert(0, project_root)

from extractor import HomeworkExtractor
from llm_evaluator import get_evaluator
from result_saver import ResultSaver

# å¯¼å…¥promptsæ¨¡å—
from config.prompts import get_prompt, get_batch_prompt
import re


class HomeworkEvaluationSystem:
    """ä½œä¸šè¯„ä»·ç³»ç»Ÿ"""

    def __init__(
        self,
        zip_path: str,
        week: str = "02",
        api_provider: str = None,
        output_dir: str = "./output"
    ):
        """
        åˆå§‹åŒ–è¯„ä»·ç³»ç»Ÿ

        Args:
            zip_path: ZIPæ–‡ä»¶è·¯å¾„
            week: å‘¨æ¬¡
            api_provider: APIæä¾›å•†
            output_dir: è¾“å‡ºç›®å½•
        """
        self.zip_path = zip_path
        self.week = week
        self.output_dir = output_dir

        # åˆå§‹åŒ–å„æ¨¡å—
        self.extractor = HomeworkExtractor(zip_path)
        self.evaluator = get_evaluator(provider=api_provider)
        self.saver = ResultSaver(output_dir=output_dir)

        # è¯„ä»·ç»“æœåˆ—è¡¨
        self.results = []

    def run(self, save_pdf: bool = True, save_excel: bool = False, save_json: bool = True):
        """
        è¿è¡Œå®Œæ•´çš„è¯„ä»·æµç¨‹

        Args:
            save_pdf: æ˜¯å¦ä¿å­˜PDFæŠ¥å‘Šï¼ˆæ¯ä¸ªå­¦ç”Ÿä¸€ä»½ï¼‰
            save_excel: æ˜¯å¦ä¿å­˜Excelæ±‡æ€»
            save_json: æ˜¯å¦ä¿å­˜JSONç»“æœ

        Returns:
            è¯„ä»·ç»“æœåˆ—è¡¨
        """
        print("=" * 60)
        print("C++ä½œä¸šè‡ªåŠ¨è¯„ä»·ç³»ç»Ÿ")
        print("=" * 60)
        print(f"ZIPæ–‡ä»¶: {self.zip_path}")
        print(f"ä½œä¸šå‘¨æ¬¡: ç¬¬{self.week}å‘¨")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 60)

        # 1. è§£å‹ZIPæ–‡ä»¶
        print("\n[æ­¥éª¤ 1/4] è§£å‹ZIPæ–‡ä»¶...")
        try:
            extract_path = self.extractor.extract_zip()
        except Exception as e:
            print(f"âœ— è§£å‹å¤±è´¥: {str(e)}")
            return []

        # 2. æ‰«æC++æ–‡ä»¶å’Œå­¦ç”Ÿåå•
        print("\n[æ­¥éª¤ 2/4] æ‰«æå­¦ç”Ÿå’Œä½œä¸šæ–‡ä»¶...")
        try:
            # è·å–æ‰€æœ‰å­¦ç”Ÿï¼ˆåŒ…æ‹¬æœªæäº¤çš„ï¼‰
            all_students = self.extractor.get_all_students()

            if not all_students:
                print("âœ— æœªæ‰¾åˆ°å­¦ç”Ÿæ–‡ä»¶å¤¹")
                return []

            # ç»Ÿè®¡æœªæäº¤ä½œä¸šçš„å­¦ç”Ÿ
            not_submitted_students = [s for s in all_students if not s['has_submission']]
            submitted_students = [s for s in all_students if s['has_submission']]

            if not_submitted_students:
                print(f"\nâš  ä»¥ä¸‹å­¦ç”Ÿæœªæäº¤ä½œä¸š:")
                for student in not_submitted_students:
                    student_name = student['student_name']
                    student_id = student.get('student_id', '')
                    print(f"   - {student_id} {student_name}" if student_id else f"   - {student_name}")
                    # è®°å½•æœªæäº¤çš„å­¦ç”Ÿ
                    self.results.append({
                        'student_name': student_name,
                        'student_id': student_id,
                        'file_name': 'æœªæäº¤',
                        'file_path': '',
                        'evaluation': 'è¯¥å­¦ç”Ÿæœªæäº¤ä½œä¸š',
                        'score': 0,
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'status': 'not_submitted'
                    })

        except Exception as e:
            print(f"âœ— æ‰«æå¤±è´¥: {str(e)}")
            return []

        # 3. æ‰¹é‡è¯„ä»·å·²æäº¤çš„ä½œä¸šï¼ˆä¼˜åŒ–ï¼šä¸€ä¸ªå­¦ç”Ÿçš„æ‰€æœ‰é¢˜ç›®ä¸€æ¬¡æ€§è¯„ä»·ï¼‰
        print(f"\n[æ­¥éª¤ 3/4] å¼€å§‹æ‰¹é‡è¯„ä»· (å…±{len(submitted_students)}ä¸ªå­¦ç”Ÿ)...")
        print("ğŸ’¡ æç¤ºï¼šç°åœ¨ä½¿ç”¨æ‰¹é‡è¯„ä»·æ¨¡å¼ï¼Œæ¯ä¸ªå­¦ç”Ÿçš„æ‰€æœ‰é¢˜ç›®ä¸€æ¬¡æ€§è¯„ä»·ï¼Œé€Ÿåº¦æ›´å¿«ï¼")
        print("ğŸ’¡ è¯„ä»·å®Œä¸€ä¸ªå­¦ç”Ÿç«‹å³ç”ŸæˆPDFï¼Œæ— éœ€ç­‰å¾…æ‰€æœ‰äººè¯„ä»·å®Œæˆ")
        print("-" * 60)

        pdf_count = 0
        for idx, student in enumerate(submitted_students, 1):
            student_name = student['student_name']
            student_id = student.get('student_id', '')
            num_problems = student['file_count']

            print(f"\n[{idx}/{len(submitted_students)}] è¯„ä»·å­¦ç”Ÿ: {student_id} {student_name} ({num_problems}é“é¢˜)")

            try:
                # æ”¶é›†è¯¥å­¦ç”Ÿçš„æ‰€æœ‰é¢˜ç›®ä»£ç 
                all_problems = []
                for file_info in student['files']:
                    file_path = file_info['file_path']
                    file_name = file_info['file_name']

                    # ä»è·¯å¾„ä¸­æå–é¢˜ç›®åç§°
                    problem_name = self._extract_problem_name(file_info['relative_path'])

                    # è¯»å–ä»£ç 
                    code = self.extractor.read_code(file_path)

                    all_problems.append({
                        'problem_name': problem_name,
                        'file_name': file_name,
                        'file_path': file_path,
                        'code': code
                    })

                # ç”Ÿæˆæ‰¹é‡è¯„ä»·æç¤ºè¯
                batch_prompt = get_batch_prompt(
                    student_name=student_name,
                    student_id=student_id,
                    all_problems=all_problems,
                    week=self.week
                )

                # ä¸€æ¬¡æ€§è°ƒç”¨APIè¯„ä»·æ‰€æœ‰é¢˜ç›®
                print(f"   æ­£åœ¨è¯„ä»· {num_problems} é“é¢˜...")
                batch_evaluation = self.evaluator.evaluate(batch_prompt)

                # è§£ææ‰¹é‡è¯„ä»·ç»“æœ
                problem_evaluations = self._parse_batch_evaluation(batch_evaluation, all_problems)

                # å‡†å¤‡è¯¥å­¦ç”Ÿçš„æ‰€æœ‰è¯„ä»·æ•°æ®
                student_evaluations = []

                # è®°å½•æ¯é“é¢˜çš„è¯„ä»·ç»“æœ
                for problem, evaluation_data in zip(all_problems, problem_evaluations):
                    result = {
                        'student_name': student_name,
                        'student_id': student_id,
                        'file_name': problem['file_name'],
                        'file_path': problem['file_path'],
                        'problem_name': problem['problem_name'],
                        'evaluation': evaluation_data['evaluation'],
                        'score': evaluation_data['score'],
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'status': 'evaluated'
                    }
                    self.results.append(result)

                    # æ·»åŠ åˆ°å­¦ç”Ÿè¯„ä»·åˆ—è¡¨ï¼ˆç”¨äºç”ŸæˆPDFï¼‰
                    student_evaluations.append({
                        'file_name': problem['file_name'],
                        'problem_name': problem['problem_name'],
                        'evaluation': evaluation_data['evaluation'],
                        'score': evaluation_data['score'],
                        'timestamp': result['timestamp']
                    })

                # è®¡ç®—å¹³å‡åˆ†
                scores = [e['score'] for e in problem_evaluations if e['score'] is not None]
                avg_score = sum(scores) / len(scores) if scores else 0
                print(f"âœ“ è¯„ä»·å®Œæˆ (å¹³å‡åˆ†: {avg_score:.1f}/100ï¼Œ{len(scores)}/{num_problems}é¢˜)")

                # ã€å…³é”®ä¿®æ”¹ã€‘è¯„ä»·å®Œç«‹å³ç”ŸæˆPDF
                if save_pdf and student_evaluations:
                    try:
                        print(f"   æ­£åœ¨ç”ŸæˆPDFæŠ¥å‘Š...")
                        self.saver.save_student_pdf(
                            student_name=student_name,
                            student_id=student_id,
                            evaluations=student_evaluations,
                            week=self.week
                        )
                        pdf_count += 1
                        print(f"âœ“ PDFæŠ¥å‘Šå·²ç”Ÿæˆ")
                    except Exception as e:
                        print(f"âš  PDFç”Ÿæˆå¤±è´¥: {str(e)}")

            except Exception as e:
                print(f"âœ— è¯„ä»·å¤±è´¥: {str(e)}")
                # è®°å½•å¤±è´¥ä¿¡æ¯ï¼ˆä¸ºè¯¥å­¦ç”Ÿçš„æ¯ä¸ªæ–‡ä»¶éƒ½è®°å½•å¤±è´¥ï¼‰
                for problem in all_problems if 'all_problems' in locals() else student['files']:
                    self.results.append({
                        'student_name': student_name,
                        'student_id': student_id,
                        'file_name': problem.get('file_name', ''),
                        'file_path': problem.get('file_path', ''),
                        'problem_name': problem.get('problem_name', ''),
                        'evaluation': f"è¯„ä»·å¤±è´¥: {str(e)}",
                        'score': None,
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'status': 'failed'
                    })

        # 4. ä¿å­˜ç»“æœ
        print(f"\n[æ­¥éª¤ 4/4] ä¿å­˜è¯„ä»·ç»“æœ...")

        print("-" * 60)

        if save_pdf:
            print(f"âœ“ å·²ç”Ÿæˆ {pdf_count} ä»½PDFæŠ¥å‘Šï¼ˆè¯„ä»·è¿‡ç¨‹ä¸­å®æ—¶ç”Ÿæˆï¼‰")

        # ä¿å­˜Excelæ±‡æ€»ï¼ˆå¯é€‰ï¼‰
        if save_excel and self.results:
            try:
                self.saver.save_summary_excel(self.results, week=self.week)
            except Exception as e:
                print(f"âœ— Excelä¿å­˜å¤±è´¥: {str(e)}")

        if save_json and self.results:
            try:
                self.saver.save_json(self.results, week=self.week)
            except Exception as e:
                print(f"âœ— JSONä¿å­˜å¤±è´¥: {str(e)}")

        # 5. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 60)
        print("è¯„ä»·å®Œæˆ!")
        print("=" * 60)

        # åˆ†ç±»ç»Ÿè®¡
        evaluated_results = [r for r in self.results if r.get('status') == 'evaluated']
        not_submitted_results = [r for r in self.results if r.get('status') == 'not_submitted']
        failed_results = [r for r in self.results if r.get('status') not in ['evaluated', 'not_submitted']]

        print(f"å­¦ç”Ÿæ€»æ•°: {len(all_students)} äºº")
        print(f"  - å·²æäº¤å¹¶è¯„ä»·: {len(set([r['student_name'] for r in evaluated_results]))} äºº")
        print(f"  - æœªæäº¤ä½œä¸š: {len(not_submitted_results)} äºº")
        if failed_results:
            print(f"  - è¯„ä»·å¤±è´¥: {len(set([r['student_name'] for r in failed_results]))} äºº")

        # åˆ†æ•°ç»Ÿè®¡ï¼ˆåªç»Ÿè®¡å·²è¯„ä»·çš„ï¼‰
        if evaluated_results:
            scores = [r['score'] for r in evaluated_results if r.get('score') is not None and r['score'] > 0]
            if scores:
                print(f"\nåˆ†æ•°ç»Ÿè®¡ï¼ˆæ‰€æœ‰é¢˜ç›®ï¼‰:")
                print(f"  - å¹³å‡åˆ†: {sum(scores) / len(scores):.1f}")
                print(f"  - æœ€é«˜åˆ†: {max(scores)}")
                print(f"  - æœ€ä½åˆ†: {min(scores)}")

        print("=" * 60)

        return self.results

    def _extract_problem_name(self, relative_path: str) -> str:
        """
        ä»ç›¸å¯¹è·¯å¾„ä¸­æå–é¢˜ç›®åç§°

        Args:
            relative_path: ç›¸å¯¹è·¯å¾„ï¼Œå¦‚"æœªåˆ†ç­/å­¦å·+å§“å/ä»£ç æ–‡ä»¶/ç¬¬1å…³-æ±‚ä¸‰ä½æ•°-186949483/main.cpp"

        Returns:
            é¢˜ç›®åç§°ï¼Œå¦‚"ç¬¬1å…³-æ±‚ä¸‰ä½æ•°"
        """
        # åˆ†å‰²è·¯å¾„
        parts = relative_path.split('/')

        # å€’æ•°ç¬¬äºŒä¸ªé€šå¸¸æ˜¯é¢˜ç›®æ–‡ä»¶å¤¹
        if len(parts) >= 2:
            problem_folder = parts[-2]
            # ç§»é™¤æœ€åçš„æ•°å­—ID (å¦‚-186949483)
            problem_name = re.sub(r'-\d+$', '', problem_folder)
            return problem_name

        return "æœªçŸ¥é¢˜ç›®"

    def _parse_batch_evaluation(self, batch_evaluation: str, all_problems: list) -> list:
        """
        è§£ææ‰¹é‡è¯„ä»·ç»“æœï¼Œæå–æ¯é“é¢˜çš„è¯„ä»·å’Œåˆ†æ•°

        Args:
            batch_evaluation: æ‰¹é‡è¯„ä»·çš„å®Œæ•´æ–‡æœ¬
            all_problems: é¢˜ç›®åˆ—è¡¨

        Returns:
            æ¯é“é¢˜çš„è¯„ä»·æ•°æ®åˆ—è¡¨
            [
                {'evaluation': 'è¯„ä»·å†…å®¹...', 'score': 85},
                ...
            ]
        """
        evaluations = []
        
        print(f"   æ­£åœ¨è§£æ {len(all_problems)} é“é¢˜çš„è¯„ä»·ç»“æœ...")
        print(f"   è¯„ä»·å†…å®¹é•¿åº¦: {len(batch_evaluation)} å­—ç¬¦")
        
        # ã€è°ƒè¯•ã€‘è¾“å‡ºAIè¿”å›çš„åŸå§‹è¯„ä»·å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰
        print(f"   AIè¿”å›å†…å®¹é¢„è§ˆ: {batch_evaluation[:500]}...")
        if len(batch_evaluation) > 500:
            print(f"   ...ï¼ˆè¿˜æœ‰ {len(batch_evaluation) - 500} ä¸ªå­—ç¬¦ï¼‰")
        
        # ã€è°ƒè¯•ã€‘æ£€æŸ¥è¯„ä»·å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–è¿‡çŸ­
        if not batch_evaluation or len(batch_evaluation.strip()) < 10:
            print(f"   âš  è­¦å‘Šï¼šAIè¿”å›çš„è¯„ä»·å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼")
            print(f"   åŸå§‹å†…å®¹: '{batch_evaluation}'")
            # ä¸ºæ¯é“é¢˜æä¾›é»˜è®¤è¯„ä»·
            for idx, problem in enumerate(all_problems):
                problem_name = problem.get('problem_name', f'é¢˜ç›®{idx+1}')
                evaluations.append({
                    'evaluation': f"ã€é¢˜ç›®{idx+1}: {problem_name}ã€‘\n\nAIè¯„ä»·å¤±è´¥ï¼Œæœªèƒ½è·å–åˆ°è¯„ä»·å†…å®¹ã€‚è¯·æ£€æŸ¥APIé…ç½®æˆ–ç½‘ç»œè¿æ¥ã€‚",
                    'score': 70  # é»˜è®¤åˆ†æ•°
                })
            return evaluations

        # ã€ä¿®å¤ã€‘æ”¹è¿›åˆ†å‰²é€»è¾‘ï¼Œæ”¯æŒå¤šç§åˆ†éš”ç¬¦æ ¼å¼
        sections = []
        
        # æ–¹æ³•1ï¼šå°è¯•æŒ‰ === åˆ†éš”
        temp_sections = re.split(r'={3,}', batch_evaluation)
        temp_sections = [s.strip() for s in temp_sections if s.strip()]
        
        if len(temp_sections) >= len(all_problems):
            sections = temp_sections
            print(f"   ä½¿ç”¨ === åˆ†éš”ç¬¦æˆåŠŸåˆ†å‰²ä¸º {len(sections)} ä¸ªéƒ¨åˆ†")
        else:
            # æ–¹æ³•2ï¼šå°è¯•æŒ‰ ### é¢˜ç›®N: åˆ†éš”
            temp_sections = re.split(r'###\s*é¢˜ç›®\s*\d+\s*[:ï¼š]', batch_evaluation)
            temp_sections = [s.strip() for s in temp_sections if s.strip()]
            
            if len(temp_sections) >= len(all_problems):
                sections = temp_sections
                print(f"   ä½¿ç”¨ ### é¢˜ç›®N: åˆ†éš”ç¬¦æˆåŠŸåˆ†å‰²ä¸º {len(sections)} ä¸ªéƒ¨åˆ†")
            else:
                # æ–¹æ³•3ï¼šå°è¯•æŒ‰é¢˜ç›®æ ‡é¢˜æ¨¡å¼åˆ†éš”
                # åŒ¹é…ç±»ä¼¼ "é¢˜ç›®1:", "ç¬¬1å…³", "ç¬¬1é¢˜" ç­‰æ¨¡å¼
                pattern = r'(?:é¢˜ç›®|ç¬¬\d+å…³|ç¬¬\d+é¢˜).*?[:ï¼š]'
                temp_sections = re.split(pattern, batch_evaluation)
                temp_sections = [s.strip() for s in temp_sections if s.strip()]
                
                if len(temp_sections) >= len(all_problems):
                    sections = temp_sections
                    print(f"   ä½¿ç”¨é¢˜ç›®æ ‡é¢˜æ¨¡å¼æˆåŠŸåˆ†å‰²ä¸º {len(sections)} ä¸ªéƒ¨åˆ†")
                else:
                    # æ–¹æ³•4ï¼šæŒ‰æ®µè½åˆ†å‰²ï¼ˆæœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼‰
                    paragraphs = batch_evaluation.split('\n\n')
                    paragraphs = [p.strip() for p in paragraphs if p.strip()]
                    
                    # å°è¯•å°†æ®µè½é‡æ–°ç»„åˆæˆé¢˜ç›®è¯„ä»·
                    if len(paragraphs) > len(all_problems):
                        # å°†æ®µè½æŒ‰é¢˜ç›®æ•°é‡å¹³å‡åˆ†é…
                        paras_per_problem = len(paragraphs) // len(all_problems)
                        sections = []
                        for i in range(len(all_problems)):
                            start_idx = i * paras_per_problem
                            end_idx = start_idx + paras_per_problem if i < len(all_problems) - 1 else len(paragraphs)
                            combined_section = '\n\n'.join(paragraphs[start_idx:end_idx])
                            sections.append(combined_section)
                        print(f"   ä½¿ç”¨æ®µè½é‡ç»„æ–¹å¼åˆ†å‰²ä¸º {len(sections)} ä¸ªéƒ¨åˆ†")
                    else:
                        sections = paragraphs
                        print(f"   ä½¿ç”¨æ®µè½åˆ†å‰²ä¸º {len(sections)} ä¸ªéƒ¨åˆ†")

        # ã€ä¿®å¤ã€‘å¦‚æœä»ç„¶åˆ†å‰²å¤±è´¥ï¼Œä½¿ç”¨æ•´ä½“è¯„ä»·ä½œä¸ºæ¯é“é¢˜çš„è¯„ä»·
        if len(sections) < len(all_problems):
            print(f"   âš  åˆ†å‰²ç»“æœä¸è¶³ï¼Œå°†ä½¿ç”¨å®Œæ•´è¯„ä»·å†…å®¹")
            # ä¸ºæ¯é“é¢˜ä½¿ç”¨å®Œæ•´çš„è¯„ä»·å†…å®¹ï¼Œå¹¶æ·»åŠ é¢˜ç›®æ ‡è¯†
            for idx, problem in enumerate(all_problems):
                problem_name = problem.get('problem_name', f'é¢˜ç›®{idx+1}')
                
                # å°è¯•ä»å®Œæ•´è¯„ä»·ä¸­æå–è¯¥é¢˜ç›®çš„ç›¸å…³å†…å®¹
                problem_evaluation = self._extract_problem_evaluation(batch_evaluation, problem_name, idx + 1)
                
                if not problem_evaluation:
                    problem_evaluation = f"ã€é¢˜ç›®{idx+1}: {problem_name}ã€‘\n\n{batch_evaluation}"
                
                score = self._extract_score(problem_evaluation)
                
                evaluations.append({
                    'evaluation': problem_evaluation,
                    'score': score if score is not None else 75  # é»˜è®¤åˆ†æ•°
                })
        else:
            # æ­£å¸¸å¤„ç†åˆ†å‰²åçš„sections
            for idx, problem in enumerate(all_problems):
                if idx < len(sections):
                    section = sections[idx]
                    
                    # ã€ä¿®å¤ã€‘ç¡®ä¿è¯„ä»·å†…å®¹å®Œæ•´
                    if len(section) < 50:  # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯åˆ†å‰²é”™è¯¯
                        print(f"   âš  é¢˜ç›®{idx+1}çš„è¯„ä»·å†…å®¹è¾ƒçŸ­ï¼Œå°è¯•è¡¥å……...")
                        # å°è¯•åˆå¹¶ç›¸é‚»çš„section
                        if idx + 1 < len(sections):
                            section = section + "\n\n" + sections[idx + 1]
                    
                    # æ·»åŠ é¢˜ç›®æ ‡è¯†ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
                    problem_name = problem.get('problem_name', f'é¢˜ç›®{idx+1}')
                    if not re.search(r'é¢˜ç›®\d+|ç¬¬\d+å…³', section):
                        section = f"ã€é¢˜ç›®{idx+1}: {problem_name}ã€‘\n\n{section}"
                    
                    # æå–åˆ†æ•°
                    score = self._extract_score(section)
                    
                    evaluations.append({
                        'evaluation': section,
                        'score': score if score is not None else 75  # é»˜è®¤åˆ†æ•°
                    })
                else:
                    # å¦‚æœæ²¡æœ‰å¯¹åº”çš„sectionï¼Œä½¿ç”¨é»˜è®¤è¯„ä»·
                    problem_name = problem.get('problem_name', f'é¢˜ç›®{idx+1}')
                    evaluations.append({
                        'evaluation': f"ã€é¢˜ç›®{idx+1}: {problem_name}ã€‘\n\nè¯¥é¢˜ç›®çš„è¯„ä»·å†…å®¹æœªèƒ½æ­£ç¡®è§£æï¼Œè¯·æ£€æŸ¥ä»£ç å®ç°ã€‚",
                        'score': 60  # é»˜è®¤åˆ†æ•°
                    })

        print(f"   âœ“ æˆåŠŸè§£æ {len(evaluations)} é“é¢˜çš„è¯„ä»·")
        return evaluations

    def _extract_problem_evaluation(self, full_evaluation: str, problem_name: str, problem_index: int) -> str:
        """
        ä»å®Œæ•´è¯„ä»·ä¸­æå–ç‰¹å®šé¢˜ç›®çš„è¯„ä»·å†…å®¹
        
        Args:
            full_evaluation: å®Œæ•´çš„è¯„ä»·æ–‡æœ¬
            problem_name: é¢˜ç›®åç§°
            problem_index: é¢˜ç›®åºå·
            
        Returns:
            è¯¥é¢˜ç›®çš„è¯„ä»·å†…å®¹
        """
        # å°è¯•å¤šç§æ¨¡å¼åŒ¹é…è¯¥é¢˜ç›®çš„è¯„ä»·
        patterns = [
            rf'###\s*é¢˜ç›®{problem_index}\s*[:ï¼š].*?(?=###\s*é¢˜ç›®\d+|$)',
            rf'é¢˜ç›®{problem_index}.*?(?=é¢˜ç›®\d+|$)',
            rf'{re.escape(problem_name)}.*?(?=ç¬¬\d+å…³|é¢˜ç›®\d+|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, full_evaluation, re.DOTALL | re.IGNORECASE)
            if match:
                content = match.group(0).strip()
                if len(content) > 50:  # ç¡®ä¿å†…å®¹è¶³å¤Ÿé•¿
                    return content
        
        return ""

    def _extract_score(self, evaluation: str) -> int:
        """
        ä»è¯„ä»·æ–‡æœ¬ä¸­æå–åˆ†æ•°

        Args:
            evaluation: è¯„ä»·æ–‡æœ¬

        Returns:
            åˆ†æ•°ï¼ˆ0-100ï¼‰ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        # ã€ä¿®å¤ã€‘æ”¹è¿›åˆ†æ•°æå–é€»è¾‘ï¼Œæ”¯æŒæ›´å¤šæ ¼å¼
        patterns = [
            r'\*\*åˆ†æ•°\*\*\s*[:ï¼š]\s*(\d+)\s*/?\\s*100',  # **åˆ†æ•°**: 85/100
            r'\*\*åˆ†æ•°\*\*\s*[:ï¼š]\s*(\d+)',              # **åˆ†æ•°**: 85
            r'åˆ†æ•°\s*[:ï¼š]\s*(\d+)\s*/\s*100',            # åˆ†æ•°: 85/100
            r'åˆ†æ•°\s*[:ï¼š]\s*(\d+)',                      # åˆ†æ•°: 85
            r'å¾—åˆ†\s*[:ï¼š]\s*(\d+)',                      # å¾—åˆ†: 85
            r'è¯„åˆ†\s*[:ï¼š]\s*(\d+)',                      # è¯„åˆ†: 85
            r'(\d+)\s*/\s*100',                          # 85/100
            r'(\d+)\s*åˆ†',                               # 85åˆ†
            r'score\s*[:ï¼š]\s*(\d+)',                    # score: 85
            r'æ€»åˆ†\s*[:ï¼š]\s*(\d+)',                     # æ€»åˆ†: 85
        ]

        for pattern in patterns:
            matches = re.findall(pattern, evaluation, re.IGNORECASE)
            if matches:
                try:
                    # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„åˆ†æ•°
                    score = int(matches[0])
                    if 0 <= score <= 100:
                        return score
                except (ValueError, IndexError):
                    continue

        # ã€æ–°å¢ã€‘å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„åˆ†æ•°ï¼Œå°è¯•ä»è¯„ä»·å†…å®¹æ¨æ–­
        evaluation_lower = evaluation.lower()
        
        # æ ¹æ®è¯„ä»·å…³é”®è¯æ¨æ–­åˆ†æ•°
        if any(word in evaluation_lower for word in ['ä¼˜ç§€', 'å¾ˆå¥½', 'å®Œç¾', 'excellent', 'perfect']):
            return 90
        elif any(word in evaluation_lower for word in ['è‰¯å¥½', 'ä¸é”™', 'good', 'well']):
            return 80
        elif any(word in evaluation_lower for word in ['ä¸€èˆ¬', 'è¿˜å¯ä»¥', 'average', 'ok']):
            return 70
        elif any(word in evaluation_lower for word in ['éœ€è¦æ”¹è¿›', 'æœ‰é—®é¢˜', 'poor', 'bad']):
            return 60
        elif any(word in evaluation_lower for word in ['å¾ˆå·®', 'é”™è¯¯å¾ˆå¤š', 'terrible', 'fail']):
            return 40
        
        # å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…ï¼Œè¿”å›Noneï¼ˆè°ƒç”¨æ–¹ä¼šä½¿ç”¨é»˜è®¤åˆ†æ•°ï¼‰
        return None


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='C++ä½œä¸šè‡ªåŠ¨è¯„ä»·ç³»ç»Ÿ')
    parser.add_argument('zip_path', help='ä½œä¸šZIPæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--week', default='02', help='ä½œä¸šå‘¨æ¬¡ (é»˜è®¤: 02)')
    parser.add_argument('--provider', choices=['openai', 'claude', 'dashscope', 'deepseek'],
                        help='APIæä¾›å•† (é»˜è®¤: ä».envè¯»å–)')
    parser.add_argument('--output', default='./output', help='è¾“å‡ºç›®å½• (é»˜è®¤: ./output)')
    parser.add_argument('--no-pdf', action='store_true', help='ä¸ç”ŸæˆPDFæŠ¥å‘Š')
    parser.add_argument('--excel', action='store_true', help='åŒæ—¶ç”ŸæˆExcelæ±‡æ€»')
    parser.add_argument('--no-json', action='store_true', help='ä¸ä¿å­˜JSONç»“æœ')

    args = parser.parse_args()

    # æ£€æŸ¥ZIPæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.zip_path):
        print(f"é”™è¯¯: ZIPæ–‡ä»¶ä¸å­˜åœ¨: {args.zip_path}")
        sys.exit(1)

    # åˆ›å»ºè¯„ä»·ç³»ç»Ÿ
    system = HomeworkEvaluationSystem(
        zip_path=args.zip_path,
        week=args.week,
        api_provider=args.provider,
        output_dir=args.output
    )

    # è¿è¡Œè¯„ä»·
    try:
        results = system.run(
            save_pdf=not args.no_pdf,
            save_excel=args.excel,
            save_json=not args.no_json
        )
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâœ— ç³»ç»Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()